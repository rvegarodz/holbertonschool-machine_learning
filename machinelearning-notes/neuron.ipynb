{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "A neural network is a machine learning model inspired by the human brain. It is a system of interconnected nodes called neurons that can learn to perform tasks by adjusting the connections between the neurons. Neural networks are used in a wide variety of applications, including image recognition, natural language processing, and speech recognition.\n",
    "\n",
    "Here is a brief explanation of how a neural network works:\n",
    "\n",
    "- The neural network is given a set of input data.\n",
    "- The input data is passed through the network, layer by layer.\n",
    "- At each layer, the neurons in the layer process the data and pass it on to the next layer.\n",
    "- The final layer of the network outputs a prediction for the input data.\n",
    "\n",
    "The weights and biases of the neurons in the network are adjusted during the training process. The goal of the training process is to find the weights and biases that minimize the error between the network's predictions and the actual output data.\n",
    "\n",
    "Neural networks are a powerful tool for machine learning, but they can be complex and difficult to train. However, recent advances in machine learning have made it possible to train neural networks on large datasets, which has led to significant improvements in the accuracy of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related resources:\n",
    "- https://www.quora.com/How-would-you-explain-neural-networks-to-someone-who-knows-very-little-about-AI-or-neurology/answer/Yohan-John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron\n",
    "\n",
    "A neuron in a neural network (ML) is a computational unit that receives inputs from other neurons, performs a mathematical operation on those inputs, and then outputs a signal to other neurons. Neurons are arranged in layers, with each layer connected to the next. The first layer receives the input data, and the final layer produces the output data.\n",
    "\n",
    "A neuron in a neural network performs a mathematical operation that consists of the following steps:\n",
    "\n",
    "- Compute the weighted sum of the inputs: The neuron takes in a set of inputs, and each input is multiplied by a weight. The weights are parameters that control how much each input contributes to the output of the neuron.\n",
    "- Add the bias: The weighted sum is then added to a bias term. The bias term is a constant that can be adjusted to fine-tune the output of the neuron.\n",
    "- Apply the activation function: The weighted sum plus the bias is then passed through an activation function. The activation function determines how the neuron responds to its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "Some common activation functions include the sigmoid function, the tanh function, and the ReLU function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "\n",
    "The sigmoid function is a mathematical function that has a characteristic \"S\"-shaped curve. The sigmoid function is defined as follows:\n",
    "\n",
    "$f(x) = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "The sigmoid function has the following properties:\n",
    "\n",
    "- It is non-linear, which means that it does not have a linear relationship between the input and output. This is important because non-linear functions allow neural networks to learn complex relationships between the input and output data.\n",
    "- It is bounded between 0 and 1, which means that the output of the function is always between 0 and 1. This is useful for classification problems, where the output of the neural network is a probability between 0 and 1.\n",
    "- It is smooth, which means that it is continuous and has no sharp edges. This is important for the training process of neural networks, as it makes the gradient of the function easier to calculate.\n",
    "\n",
    "The sigmoid function is a popular activation function for neural networks because it has these desirable properties. However, it can also be computationally expensive to evaluate, especially for large neural networks. In recent years, there has been a trend towards using other activation functions, such as the ReLU function, which are faster to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related resources:\n",
    "- https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's Cost\n",
    "\n",
    "In logistic regression, the cost of the model is calculated using the cross-entropy loss function. The cross-entropy loss function is a measure of how well the model predicts the output data. The lower the cross-entropy loss, the better the model predicts the output data.\n",
    "\n",
    "The cross-entropy loss function is calculated for each data point in the training set. The overall cost of the model is the average of the cross-entropy loss for all data points in the training set. The cost of the model is used to update the weights and biases of the model during the training process. The goal of the training process is to minimize the cost of the model.\n",
    "\n",
    "In the context of a neuron in a neural network, the cost of the model is calculated using the same cross-entropy loss function. The weights and biases of the neuron are updated to minimize the cost of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy loss function\n",
    "\n",
    "total_cost = -1/m * sum(y_i * log(a_i) + (1 - y_i) * log(1 - a_i))\n",
    "\n",
    "where:\n",
    "\n",
    "- m is the number of data points in the training set\n",
    "    - m = the number of columns in the Y array\n",
    "- y_i is the true label for the i-th data point\n",
    "    - y_i = is a numpy.ndarray with shape (1, m) that contains the correct labels for the input data\n",
    "- a_i is the predicted probability for the i-th data point\n",
    "    - is a numpy.ndarray with shape (1, m) containing the activated output of the neuron for each example\n",
    "- log() is the natural logarithm function\n",
    "\n",
    "The -1/m term is a normalization term that ensures that the cost is not too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
